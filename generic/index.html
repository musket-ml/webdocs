<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>User guide - Musket ML</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700" />

  <link rel="stylesheet" href="../css/theme.css" />
  <link rel="stylesheet" href="../css/theme_extra.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" />
  
  <script>
    // Current page data
    var mkdocs_page_name = "User guide";
    var mkdocs_page_input_path = "generic\\index.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../js/jquery-2.1.1.min.js" defer></script>
  <script src="../js/modernizr-2.8.3.min.js" defer></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/Python.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> Musket ML</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
                <p class="caption"><span class="caption-text">Generic</span></p>
                <ul class="current">
                    <li class="toctree-l1 current"><a class="reference internal current" href="./">User guide</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#reasons-to-use-generic-pipeline">Reasons to use Generic Pipeline</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#installation">Installation</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#prerequisites">Prerequisites</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#choosing-your-installation-type">Choosing your installation type</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#global-pip-installation">Global pip installation</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#virtual-environment-installation-recommended">Virtual environment installation (recommended)</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#virtualenv-installation-recommended">virtualenv installation (recommended)</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#pipenv-installation">pipenv installation</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#other-packages">Other packages</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#project-structure">Project structure</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#launching">Launching</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#launching-experiments">Launching experiments</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#launching-tasks">Launching tasks</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#launching-project-analysis">Launching project analysis</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#general-train-properties">General train properties</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#definining-networks">Definining networks</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#built-in-nn-layers">Built-in NN layers</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#control-layers">Control layers</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#simple-data-flow-constructions">Simple Data Flow constructions</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#repeat-and-with">Repeat and With</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#conditional-layers">Conditional layers</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#shared-weights">Shared Weights</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#wrapper-layers">Wrapper layers</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#manually-controlling-data-flow">Manually controlling data flow</a>
    </li>
        </ul>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#datasets">Datasets</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#callbacks">Callbacks</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#stages">Stages</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#balancing-your-data">Balancing your data</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#advanced-learning-rates">Advanced learning rates</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#dynamic-learning-rates">Dynamic learning rates</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#lr-finder">LR Finder</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#preprocessors">Preprocessors</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#how-to-check-training-results">How to check training results</a>
    </li>
    </ul>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="reference/">Reference</a>
    <ul>
    <li class="toctree-l2"><a class="reference internal" href="reference/#pipeline-root-properties">Pipeline root properties</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="reference/#experiment_result">experiment_result</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#architecture">architecture</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#batch">batch</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#callbacks">callbacks</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#copyweights">copyWeights</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#clipnorm">clipnorm</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#clipvalue">clipvalue</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#dataset">dataset</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#datasets">datasets</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#declarations">declarations</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#extra_train_data">extra_train_data</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#folds_count">folds_count</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#final_metrics">final_metrics</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#imports">imports</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#inference_batch">inference_batch</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#loss">loss</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#lr">lr</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#metrics">metrics</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#num_seeds">num_seeds</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#optimizer">optimizer</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#primary_metric">primary_metric</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#primary_metric_mode">primary_metric_mode</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#preprocessing">preprocessing</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#random_state">random_state</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#stages">stages</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#stratified">stratified</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#testsplit">testSplit</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#testsplitseed">testSplitSeed</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#testtimeaugmentation">testTimeAugmentation</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#validationsplit">validationSplit</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="reference/#callback-types">Callback types</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="reference/#earlystopping">EarlyStopping</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#reducelronplateau">ReduceLROnPlateau</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#cycliclr">CyclicLR</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#lrvariator">LRVariator</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#tensorboard">TensorBoard</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="reference/#layer-types">Layer types</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="reference/#input">Input</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#gaussiannoise">GaussianNoise</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#dropout">Dropout</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#spatialdropout1d">SpatialDropout1D</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#lstm">LSTM</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#globalmaxpool1d">GlobalMaxPool1D</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#globalaveragepooling1d">GlobalAveragePooling1D</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#batchnormalization">BatchNormalization</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#concatenate">Concatenate</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#add">Add</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#substract">Substract</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#mult">Mult</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#max">Max</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#min">Min</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#conv1d">Conv1D</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#conv2d">Conv2D</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#maxpool1d">MaxPool1D</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#maxpool2d">MaxPool2D</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#averagepooling1d">AveragePooling1D</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#cudnnlstm">CuDNNLSTM</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#dense">Dense</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#flatten">Flatten</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#bidirectional">Bidirectional</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="reference/#utility-layers">Utility layers</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="reference/#split">split</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#split-concat">split-concat</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#split-concatenate">split-concatenate</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#split-add">split-add</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#split-substract">split-substract</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#split-mult">split-mult</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#split-min">split-min</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#split-max">split-max</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#split-dot">split-dot</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#split-dot-normalize">split-dot-normalize</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#seq">seq</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#input_1">input</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#pass">pass</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#transform-concat">transform-concat</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#transform-add">transform-add</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="reference/#stage-properties">Stage properties</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="reference/#callbacks_1">callbacks</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#epochs">epochs</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#extra_callbacks">extra_callbacks</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#initial_weights">initial_weights</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#negatives">negatives</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#loss_1">loss</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#lr_1">lr</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#validation_negatives">validation_negatives</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="reference/#preprocessors">Preprocessors</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="reference/#cache">cache</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#disk-cache">disk-cache</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#split-preprocessor">split-preprocessor</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#split-concat-preprocessor">split-concat-preprocessor</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#seq-preprocessor">seq-preprocessor</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#augmentation">augmentation</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="reference/#fit-script-arguments">fit script arguments</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="reference/#fitpy-project">fit.py project</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#fitpy-name">fit.py name</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#fitpy-num_gpus">fit.py num_gpus</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#fitpy-gpus_per_net">fit.py gpus_per_net</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#fitpy-num_workers">fit.py num_workers</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#fitpy-allow_resume">fit.py allow_resume</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#fitpy-force_recalc">fit.py force_recalc</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#fitpy-launch_tasks">fit.py launch_tasks</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#fitpy-only_report">fit.py only_report</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#fitpy-cache">fit.py cache</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#fitpy-folds">fit.py folds</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="reference/#task-script-arguments">task script arguments</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="reference/#taskpy-project">task.py project</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#taskpy-name">task.py name</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#taskpy-task">task.py task</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#taskpy-num_gpus">task.py num_gpus</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#taskpy-gpus_per_net">task.py gpus_per_net</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#taskpy-num_workers">task.py num_workers</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#taskpy-allow_resume">task.py allow_resume</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#taskpy-force_recalc">task.py force_recalc</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#taskpy-launch_tasks">task.py launch_tasks</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#taskpy-cache">task.py cache</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="reference/#analyze-script-arguments">analyze script arguments</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="reference/#analyzepy-inputfolder">analyze.py inputFolder</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#analyzepy-output">analyze.py output</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#analyzepy-onlymetric">analyze.py onlyMetric</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="reference/#analyzepy-sortby">analyze.py sortBy</a>
    </li>
        </ul>
    </li>
    </ul>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Segmentation</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../segmentation/getting_started/">Getting started</a>
    <ul>
    <li class="toctree-l2"><a class="reference internal" href="../segmentation/getting_started/#installing-kaggle-stuff">Installing kaggle stuff</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../segmentation/getting_started/#downloading-tgs-salt-competition-dataset">Downloading TGS Salt competition dataset</a>
    </li>
    </ul>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../segmentation/">User guide</a>
    <ul>
    <li class="toctree-l2"><a class="reference internal" href="../segmentation/#reasons-to-use-segmentation-pipeline">Reasons to use Segmentation Pipeline</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../segmentation/#installation">Installation</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../segmentation/#launching">Launching</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/#launching-experiments">Launching experiments</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/#launching-tasks">Launching tasks</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/#launching-project-analysis">Launching project analysis</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../segmentation/#usage-guide">Usage guide</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/#training-a-model">Training a model</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="../segmentation/#general-train-properties">General train properties</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="../segmentation/#defining-architecture">Defining architecture</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="../segmentation/#image-and-mask-augmentations">Image and Mask Augmentations</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="../segmentation/#freezing-and-unfreezing-encoder">Freezing and Unfreezing encoder</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="../segmentation/#custom-datasets">Custom datasets</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="../segmentation/#multistage-training">Multistage training</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="../segmentation/#balancing-your-data">Balancing your data</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="../segmentation/#advanced-learning-rates">Advanced learning rates</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="../segmentation/#training-on-crops">Training on crops</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/#using-trained-model">Using trained model</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="../segmentation/#ensembling-predictions">Ensembling predictions</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/#custom-evaluation-code">Custom evaluation code</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/#accessing-model">Accessing model</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../segmentation/#analyzing-experiments-results">Analyzing experiments results</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../segmentation/#what-is-supported">What is supported?</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../segmentation/#custom-architectures-callbacks-metrics">Custom architectures, callbacks, metrics</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../segmentation/#examples">Examples</a>
    </li>
    </ul>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../segmentation/reference/">Reference</a>
    <ul>
    <li class="toctree-l2"><a class="reference internal" href="../segmentation/reference/#pipeline-root-properties">Pipeline root properties</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#activation">activation</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#experiment_result">experiment_result</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#architecture">architecture</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#augmentation">augmentation</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#backbone">backbone</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#batch">batch</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#classifier">classifier</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#classes">classes</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#callbacks">callbacks</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#compresspredictionsasints">compressPredictionsAsInts</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#copyweights">copyWeights</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#clipnorm">clipnorm</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#clipvalue">clipvalue</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#crops">crops</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#dataset">dataset</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#datasets">datasets</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#dataset_augmenter">dataset_augmenter</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#dropout">dropout</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#encoder_weights">encoder_weights</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#extra_train_data">extra_train_data</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#folds_count">folds_count</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#freeze_encoder">freeze_encoder</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#final_metrics">final_metrics</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#holdout">holdout</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#imports">imports</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#inference_batch">inference_batch</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#loss">loss</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#lr">lr</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#manualresize">manualResize</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#metrics">metrics</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#num_seeds">num_seeds</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#optimizer">optimizer</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#primary_metric">primary_metric</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#primary_metric_mode">primary_metric_mode</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#preprocessing">preprocessing</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#random_state">random_state</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#shape">shape</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#stages">stages</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#stratified">stratified</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#testsplit">testSplit</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#testsplitseed">testSplitSeed</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#testtimeaugmentation">testTimeAugmentation</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#transforms">transforms</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#validationsplit">validationSplit</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../segmentation/reference/#callback-types">Callback types</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#earlystopping">EarlyStopping</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#reducelronplateau">ReduceLROnPlateau</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#cycliclr">CyclicLR</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#lrvariator">LRVariator</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#tensorboard">TensorBoard</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../segmentation/reference/#stage-properties">Stage properties</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#callbacks_1">callbacks</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#epochs">epochs</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#extra_callbacks">extra_callbacks</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#freeze_encoder_1">freeze_encoder</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#initial_weights">initial_weights</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#negatives">negatives</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#loss_1">loss</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#lr_1">lr</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#unfreeze_encoder">unfreeze_encoder</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#validation_negatives">validation_negatives</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../segmentation/reference/#preprocessors">Preprocessors</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#cache">cache</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#disk-cache">disk-cache</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#split-preprocessor">split-preprocessor</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#split-concat-preprocessor">split-concat-preprocessor</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#seq-preprocessor">seq-preprocessor</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#augmentation_1">augmentation</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../segmentation/reference/#fit-script-arguments">fit script arguments</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#fitpy-project">fit.py project</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#fitpy-name">fit.py name</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#fitpy-num_gpus">fit.py num_gpus</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#fitpy-gpus_per_net">fit.py gpus_per_net</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#fitpy-num_workers">fit.py num_workers</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#fitpy-allow_resume">fit.py allow_resume</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#fitpy-force_recalc">fit.py force_recalc</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#fitpy-launch_tasks">fit.py launch_tasks</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#fitpy-only_report">fit.py only_report</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#fitpy-cache">fit.py cache</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#fitpy-folds">fit.py folds</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#fitpy-time">fit.py time</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../segmentation/reference/#task-script-arguments">task script arguments</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#taskpy-project">task.py project</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#taskpy-name">task.py name</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#taskpy-task">task.py task</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#taskpy-num_gpus">task.py num_gpus</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#taskpy-gpus_per_net">task.py gpus_per_net</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#taskpy-num_workers">task.py num_workers</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#taskpy-allow_resume">task.py allow_resume</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#taskpy-force_recalc">task.py force_recalc</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#taskpy-launch_tasks">task.py launch_tasks</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#taskpy-cache">task.py cache</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../segmentation/reference/#analyze-script-arguments">analyze script arguments</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#analyzepy-inputfolder">analyze.py inputFolder</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#analyzepy-output">analyze.py output</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#analyzepy-onlymetric">analyze.py onlyMetric</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../segmentation/reference/#analyzepy-sortby">analyze.py sortBy</a>
    </li>
        </ul>
    </li>
    </ul>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Classification</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../classification/">User guide</a>
    <ul>
    <li class="toctree-l2"><a class="reference internal" href="../classification/#reasons-to-use-classification-pipeline">Reasons to use Classification Pipeline</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../classification/#installation">Installation</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../classification/#launching">Launching</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="../classification/#launching-experiments">Launching experiments</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/#launching-tasks">Launching tasks</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/#launching-project-analysis">Launching project analysis</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../classification/#usage-guide">Usage guide</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="../classification/#training-a-model">Training a model</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="../classification/#general-train-properties">General train properties</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="../classification/#defining-architecture">Defining architecture</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="../classification/#image-augmentations">Image Augmentations</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="../classification/#freezing-and-unfreezing-encoder">Freezing and Unfreezing encoder</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="../classification/#custom-datasets">Custom datasets</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/#multi-output-classification">Multi output classification</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="../classification/#preparing-dataset-for-multi-output-classification">preparing dataset for multi output classification:</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="../classification/#balancing-your-data">Balancing your data</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="../classification/#advanced-learning-rates">Advanced learning rates</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="../classification/#training-on-crops">Training on crops</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/#using-trained-model">Using trained model</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="../classification/#ensembling-predictions">Ensembling predictions</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/#custom-evaluation-code">Custom evaluation code</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/#accessing-model">Accessing model</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../classification/#analyzing-experiments-results">Analyzing experiments results</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../classification/#what-is-supported">What is supported?</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../classification/#custom-architectures-callbacks-metrics">Custom architectures, callbacks, metrics</a>
    </li>
    </ul>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../classification/reference/">Reference</a>
    <ul>
    <li class="toctree-l2"><a class="reference internal" href="../classification/reference/#pipeline-root-properties">Pipeline root properties</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#activation">activation</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#experiment_result">experiment_result</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#architecture">architecture</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#augmentation">augmentation</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#batch">batch</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#classes">classes</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#callbacks">callbacks</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#copyweights">copyWeights</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#clipnorm">clipnorm</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#clipvalue">clipvalue</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#crops">crops</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#dataset">dataset</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#datasets">datasets</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#dataset_augmenter">dataset_augmenter</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#dropout">dropout</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#extra_train_data">extra_train_data</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#folds_count">folds_count</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#freeze_encoder">freeze_encoder</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#final_metrics">final_metrics</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#holdout">holdout</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#imports">imports</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#inference_batch">inference_batch</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#loss">loss</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#lr">lr</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#manualresize">manualResize</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#metrics">metrics</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#num_seeds">num_seeds</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#optimizer">optimizer</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#primary_metric">primary_metric</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#primary_metric_mode">primary_metric_mode</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#preprocessing">preprocessing</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#random_state">random_state</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#shape">shape</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#stages">stages</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#stratified">stratified</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#testsplit">testSplit</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#testsplitseed">testSplitSeed</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#testtimeaugmentation">testTimeAugmentation</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#transforms">transforms</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#validationsplit">validationSplit</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#weights">weights</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../classification/reference/#callback-types">Callback types</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#earlystopping">EarlyStopping</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#reducelronplateau">ReduceLROnPlateau</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#cycliclr">CyclicLR</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#lrvariator">LRVariator</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#tensorboard">TensorBoard</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../classification/reference/#stage-properties">Stage properties</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#callbacks_1">callbacks</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#epochs">epochs</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#extra_callbacks">extra_callbacks</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#freeze_encoder_1">freeze_encoder</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#initial_weights">initial_weights</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#negatives">negatives</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#loss_1">loss</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#lr_1">lr</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#unfreeze_encoder">unfreeze_encoder</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#validation_negatives">validation_negatives</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../classification/reference/#preprocessors">Preprocessors</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#cache">cache</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#disk-cache">disk-cache</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#split-preprocessor">split-preprocessor</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#split-concat-preprocessor">split-concat-preprocessor</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#seq-preprocessor">seq-preprocessor</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#augmentation_1">augmentation</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../classification/reference/#fit-script-arguments">fit script arguments</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#fitpy-project">fit.py project</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#fitpy-name">fit.py name</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#fitpy-num_gpus">fit.py num_gpus</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#fitpy-gpus_per_net">fit.py gpus_per_net</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#fitpy-num_workers">fit.py num_workers</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#fitpy-allow_resume">fit.py allow_resume</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#fitpy-force_recalc">fit.py force_recalc</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#fitpy-launch_tasks">fit.py launch_tasks</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#fitpy-only_report">fit.py only_report</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#fitpy-cache">fit.py cache</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#fitpy-folds">fit.py folds</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../classification/reference/#task-script-arguments">task script arguments</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#taskpy-project">task.py project</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#taskpy-name">task.py name</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#taskpy-task">task.py task</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#taskpy-num_gpus">task.py num_gpus</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#taskpy-gpus_per_net">task.py gpus_per_net</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#taskpy-num_workers">task.py num_workers</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#taskpy-allow_resume">task.py allow_resume</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#taskpy-force_recalc">task.py force_recalc</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#taskpy-launch_tasks">task.py launch_tasks</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#taskpy-cache">task.py cache</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../classification/reference/#analyze-script-arguments">analyze script arguments</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#analyzepy-inputfolder">analyze.py inputFolder</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#analyzepy-output">analyze.py output</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#analyzepy-onlymetric">analyze.py onlyMetric</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../classification/reference/#analyzepy-sortby">analyze.py sortBy</a>
    </li>
        </ul>
    </li>
    </ul>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Instance Segmentation (alpha)</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../instance_segmentation/">User guide</a>
    <ul>
    <li class="toctree-l2"><a class="reference internal" href="../instance_segmentation/#installation">Installation</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../instance_segmentation/#launching">Launching</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../instance_segmentation/#launching-experiments">Launching experiments</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/#launching-tasks">Launching tasks</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/#launching-project-analysis">Launching project analysis</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../instance_segmentation/#usage-guide">Usage guide</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/#dataset-format">Dataset format</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/#training-a-model">Training a model</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="../instance_segmentation/#general-train-properties">General train properties</a>
    </li>
        </ul>
    </li>
        </ul>
    </li>
    </ul>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../instance_segmentation/reference/">Reference</a>
    <ul>
    <li class="toctree-l2"><a class="reference internal" href="../instance_segmentation/reference/#pipeline-root-properties">Pipeline root properties</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#classes">classes</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#configpath">configPath</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#dataset">dataset</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#datasets">datasets</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#folds_count">folds_count</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#holdout">holdout</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#imagespergpu">imagesPerGpu</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#imports">imports</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#multiscalemode">multiscaleMode</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#num_seeds">num_seeds</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#preprocessing">preprocessing</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#random_state">random_state</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#shape">shape</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#stages">stages</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#stratified">stratified</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#testsplit">testSplit</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#testsplitseed">testSplitSeed</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#validationsplit">validationSplit</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#weightspath">weightsPath</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../instance_segmentation/reference/#stage-properties">Stage properties</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#epochs">epochs</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../instance_segmentation/reference/#preprocessors">Preprocessors</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#cache">cache</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#disk-cache">disk-cache</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#split-preprocessor">split-preprocessor</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#split-concat-preprocessor">split-concat-preprocessor</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#seq-preprocessor">seq-preprocessor</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#augmentation">augmentation</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../instance_segmentation/reference/#fit-script-arguments">fit script arguments</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#fitpy-project">fit.py project</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#fitpy-name">fit.py name</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#fitpy-num_gpus">fit.py num_gpus</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#fitpy-gpus_per_net">fit.py gpus_per_net</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#fitpy-num_workers">fit.py num_workers</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#fitpy-allow_resume">fit.py allow_resume</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#fitpy-force_recalc">fit.py force_recalc</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#fitpy-launch_tasks">fit.py launch_tasks</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#fitpy-only_report">fit.py only_report</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#fitpy-cache">fit.py cache</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#fitpy-folds">fit.py folds</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../instance_segmentation/reference/#task-script-arguments">task script arguments</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#taskpy-project">task.py project</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#taskpy-name">task.py name</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#taskpy-task">task.py task</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#taskpy-num_gpus">task.py num_gpus</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#taskpy-gpus_per_net">task.py gpus_per_net</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#taskpy-num_workers">task.py num_workers</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#taskpy-allow_resume">task.py allow_resume</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#taskpy-force_recalc">task.py force_recalc</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#taskpy-launch_tasks">task.py launch_tasks</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#taskpy-cache">task.py cache</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../instance_segmentation/reference/#analyze-script-arguments">analyze script arguments</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#analyzepy-inputfolder">analyze.py inputFolder</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#analyzepy-output">analyze.py output</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#analyzepy-onlymetric">analyze.py onlyMetric</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../instance_segmentation/reference/#analyzepy-sortby">analyze.py sortBy</a>
    </li>
        </ul>
    </li>
    </ul>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Text</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../text/">About</a>
    <ul>
    <li class="toctree-l2"><a class="reference internal" href="../text/#installation">Installation</a>
    </li>
    </ul>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Musket IDE</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../ide/getting_started/">Getting started</a>
    <ul>
    <li class="toctree-l2"><a class="reference internal" href="../ide/getting_started/#download">Download</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="../ide/getting_started/#nightly-builds">Nightly builds:</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../ide/getting_started/#installation">Installation</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../ide/getting_started/#watch-this-in-action">Watch this in action</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../ide/getting_started/#setting-up-a-project">Setting up a project</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../ide/getting_started/#getting-dataset-from-kaggle">Getting dataset from Kaggle</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="../ide/getting_started/#installing-kaggle-stuff">Installing kaggle stuff</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="../ide/getting_started/#downloading-the-dataset">Downloading the dataset</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../ide/getting_started/#analysing-dataset">Analysing dataset</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../ide/getting_started/#creating-an-experiment">Creating an experiment</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../ide/getting_started/#editing-an-experiment">Editing an experiment</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../ide/getting_started/#running-an-experiment">Running an experiment</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../ide/getting_started/#checking-results-and-logs">Checking results and logs</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../ide/getting_started/#checking-predictions">Checking predictions</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="../ide/getting_started/#what-is-next">What is next</a>
    </li>
    </ul>
                    </li>
                </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">Musket ML</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
        
          <li>Generic &raquo;</li>
        
      
    
    <li>User guide</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="generic-pipeline">Generic pipeline</h1>
<h2 id="reasons-to-use-generic-pipeline">Reasons to use Generic Pipeline</h2>
<p>Generic Pipeline was developed with a focus of enabling to make fast and 
simply-declared experiments, which can be easily stored, 
reproduced and compared to each other.</p>
<p>It provides the following features:</p>
<ul>
<li>Allows to describe experiments in a compact and expressive way</li>
<li>Provides a way to store and compare experiments in order to methodically find the best deap learning solution</li>
<li>Easy to share experiments and their results to work in a team</li>
<li>Experiment configurations are separated from model definitions</li>
<li>Allows to define custom neural networks in a declarative style, by building it from blocks</li>
<li>Provides great flexibility and extensibility via support of custom substances</li>
<li>Common blocks like an architecture, callbacks, model metrics, predictions vizualizers and others should be written once and be a part of a common library</li>
</ul>
<p>All experiments are declared in YAML dialect with lots of defaults, allowing to describe an initial experiment in several lines and then set more details if needed.</p>
<p>Here is a relatively complex example, most of the statements can be omitted:</p>
<pre><code class="yaml">imports: [ layers, preprocessors ]
declarations:
  collapseConv:
    parameters: [ filters,size, pool]
    body:
      - conv1d: [filters,size,relu ]
      - conv1d: [filters,size,relu ]
      - batchNormalization: {}
      - collapse: pool
  net:
    - repeat(2):
      - collapseConv: [ 20, 7, 10 ]

    - cudnnlstm: [40, true ]
    - cudnnlstm: [40, true ]
    - attention: 718
    - dense: [3, sigmoid]
  preprocess:
     - rescale: 10
     - get_delta_from_average
     - cache
preprocessing: preprocess
testSplit: 0.4
architecture: net
optimizer: Adam #Adam optimizer is a good default choice
batch: 12 #Our batch size will be 16
metrics: #We would like to track some metrics
  - binary_accuracy
  - matthews_correlation
primary_metric: val_binary_accuracy #and the most interesting metric is val_binary_accuracy
callbacks: #Let's configure some minimal callbacks
  EarlyStopping:
    patience: 100
    monitor: val_binary_accuracy
    verbose: 1
  ReduceLROnPlateau:
    patience: 8
    factor: 0.5
    monitor: val_binary_accuracy
    mode: auto
    cooldown: 5
    verbose: 1
loss: binary_crossentropy #We use simple binary_crossentropy loss
stages:
  - epochs: 100 #Let's go for 100 epochs
  - epochs: 100 #Let's go for 100 epochs
  - epochs: 100 #Let's go for 100 epochs
</code></pre>

<h2 id="installation">Installation</h2>
<h3 id="prerequisites">Prerequisites</h3>
<p>The package has many prerequisites, but some of them are 
recommended to be installed manually.</p>
<p>Tensorflow package of versions of 1.14 and below split into CPU and GPU ones.
Moreover, Tensorflow may be more or less compatible with the version of 
CUDA/CUDNN installed.</p>
<p>Here is the repository containing lots of pre-built Tensorflow 
wheels for Windows: <a href="https://github.com/fo40225/tensorflow-windows-wheel">tensorflow-windows-wheel</a>.
It can be used to choose the wheel depending on system architecture, 
CUDA/CUDNN version, CPU/GPU and Python version.</p>
<p>Read more in <a href="https://www.tensorflow.org/install/pip">Tensorflow installation guide</a>.</p>
<p>Keras has no strong dependency on Tensorflow, but in our common setup they run in pair.
We used the 2.2.4 one.</p>
<p>Shapely requires compilation on install on Linux/MacOS or pre-built version on Windows.
Here are the <a href="https://www.lfd.uci.edu/~gohlke/pythonlibs/#shapely">pre-built Shapely wheels for Windows</a>. </p>
<h3 id="choosing-your-installation-type">Choosing your installation type</h3>
<p>It is recommended to install to a virtual environment in order to avoid dependency version conflicts.</p>
<h3 id="global-pip-installation">Global pip installation</h3>
<p>Install Tensorflow, Keras and Shapely as described in pre-requisites.
In example, if you have downloaded particular 
Tensorflow wheel into <code>C:\downloads\tensorflow_gpu-1.12.0-cp36-cp36m-win_amd64.whl</code> 
and particular Shapely wheel into <code>C:\downloads\Shapely-1.6.4.post1-cp36-cp36m-win_amd64.whl</code>, run:</p>
<pre><code>pip install C:\downloads\tensorflow_gpu-1.12.0-cp36-cp36m-win_amd64.whl
pip install Keras==2.2.4
pip install C:\downloads\Shapely-1.6.4.post1-cp36-cp36m-win_amd64.whl
</code></pre>

<pre><code>pip install musket_ml 
</code></pre>

<h3 id="virtual-environment-installation-recommended">Virtual environment installation (recommended)</h3>
<h4 id="virtualenv-installation-recommended">virtualenv installation (recommended)</h4>
<p>This type of installation uses virtualenv manager for 
creating your virtual environment.</p>
<p>Create a new virtual environment:</p>
<pre><code>virtualenv ./musket
</code></pre>

<p>This will create <code>musket</code> folder and place a copy of your python, pip and wheel inside.</p>
<p>Activate the new virtual environment:</p>
<p>On Posix systems:</p>
<pre><code>source ./musket/bin/activate
</code></pre>

<p>On Windows:</p>
<pre><code>.\musket\Scripts\activate
</code></pre>

<p>Install Tensorflow, Keras and Shapely as described in pre-requisites.
In example, if you have downloaded particular 
Tensorflow wheel into <code>C:\downloads\tensorflow_gpu-1.12.0-cp36-cp36m-win_amd64.whl</code> 
and particular Shapely wheel into <code>C:\downloads\Shapely-1.6.4.post1-cp36-cp36m-win_amd64.whl</code>, run:</p>
<pre><code>pip install C:\downloads\tensorflow_gpu-1.12.0-cp36-cp36m-win_amd64.whl
pip install Keras==2.2.4
pip install C:\downloads\Shapely-1.6.4.post1-cp36-cp36m-win_amd64.whl
</code></pre>

<p>Now install musket:</p>
<pre><code>pip install musket_ml 
</code></pre>

<p>Experiment launches and other activity should be performed when this environment is activated.</p>
<p>When you are done working with musket, you can deactivate the environment by 
launching:</p>
<pre><code>virtualenv deactivate
</code></pre>

<h4 id="pipenv-installation">pipenv installation</h4>
<p>This type of installation uses pipenv manager for 
creating your virtual environment.</p>
<p>Install pipenv if needed:</p>
<pre><code>pip install --user pipenv
</code></pre>

<p>Create new environment by launching:</p>
<pre><code>mkdir musket
cd musket
pipenv --python 3.6
</code></pre>

<p>Install Tensorflow, Keras and Shapely as described in pre-requisites.
In example, if you have downloaded particular 
Tensorflow wheel into <code>C:\downloads\tensorflow_gpu-1.12.0-cp36-cp36m-win_amd64.whl</code> 
and particular Shapely wheel into <code>C:\downloads\Shapely-1.6.4.post1-cp36-cp36m-win_amd64.whl</code>, run:</p>
<pre><code>pipenv install C:\downloads\tensorflow_gpu-1.12.0-cp36-cp36m-win_amd64.whl
pipenv install Keras==2.2.4
pipenv install C:\downloads\Shapely-1.6.4.post1-cp36-cp36m-win_amd64.whl
</code></pre>

<p>Now install musket:</p>
<pre><code>pipenv install musket_ml 
</code></pre>

<p>Experiment launches and other activity should be performed 
when this environment is activated or using pipenv.</p>
<p>So, the first approach is to activate the environment by launching</p>
<pre><code>pipenv shell
</code></pre>

<p>while inside <code>musket</code> folder.</p>
<p>Or, alternativelly, prefix all experiment management commands with </p>
<p><code>pipenv run</code>,</p>
<p>in example, instead of running</p>
<p><code>musket fit --project "D:\work\salt" --name "exp01" --num_gpus=1 --gpus_per_net=1 --num_workers=1 --cache "D:\work\salt\data\cache"</code></p>
<p>run</p>
<p><code>pipenv run musket fit --project "D:\work\salt" --name "exp01" --num_gpus=1 --gpus_per_net=1 --num_workers=1 --cache "D:\work\salt\data\cache"</code></p>
<h3 id="other-packages">Other packages</h3>
<p><code>musket_ml</code> joins all mainstream pipelines that belong to Musket-ML framework.
In particular, besides <code>musket_core</code> generic pipeline, it includes 
<code>classification_pipeline</code> <a href="../classification/">classification pipeline</a>,
<code>segmentation_pipeline</code> <a href="../segmentation/">segmentation pipeline</a>
 and <code>musket_text</code> <a href="../text/">text support</a>.</p>
<p>To install only the generic pipeline, follow the same instructions, 
but use <code>musket_core</code> wheel instead of <code>musket_ml</code>.</p>
<h2 id="project-structure">Project structure</h2>
<p>Each experiment is simply a folder with YAML file inside, it is easy to store and run experiment.</p>
<p>Project is a folder with the following structure inside:</p>
<ul>
<li><strong>project_name</strong></li>
<li><strong>experiments</strong><ul>
<li><strong>experiment1</strong></li>
<li>config.yaml</li>
<li><strong>experiment2</strong></li>
<li>config.yaml</li>
<li>summary.yaml</li>
<li><strong>metrics</strong><ul>
<li>metrics-0.0.csv</li>
<li>metrics-1.0.csv</li>
<li>metrics-2.0.csv</li>
<li>metrics-3.0.csv</li>
<li>metrics-4.0.csv</li>
</ul>
</li>
</ul>
</li>
<li><strong>modules</strong><ul>
<li>main.py</li>
<li>arbitrary_module.py</li>
</ul>
</li>
<li>common.yaml</li>
</ul>
<p>The only required part is <code>experiments</code> folder with at least one arbitrary-named experiment subfolder having <code>config.yaml</code> file inside.
Each experiment starts with its configuration, other files are being added by the pipeline during th training.</p>
<p><code>common.yaml</code> file may be added to set instructions, which will be applied to all project experiments.</p>
<p><code>modules</code> folder may be added to set python files in project scope, so custom yaml declarations can be mapped 
onto python classes and functions defined inside such files. all modules in this folder will be always executed, other modules require <a href="reference/#imports">imports</a> instruction. </p>
<p><code>summary.yaml</code> and <code>metrics</code> folders inside each experiment appear after the experiment training is executed.</p>
<p>There are more potential files, like intermediate results cache files etc.</p>
<h2 id="launching">Launching</h2>
<h3 id="launching-experiments">Launching experiments</h3>
<p><code>fit.py</code> script is designed to launch experiment training.</p>
<p>In order to run the experiment or a number of experiments,   </p>
<p>A typical command line may look like this:</p>
<p><code>musket fit --project "path/to/project" --name "experiment_name" --num_gpus=1 --gpus_per_net=1 --num_workers=1 --cache "path/to/cache/folder"</code></p>
<p><a href="reference/#fitpy-project">--project</a> points to the root of the <a href="#project-structure">project</a></p>
<p><a href="reference/#fitpy-name">--name</a> is the name of the project sub-folder containing experiment yaml file.</p>
<p><a href="reference/#fitpy-num_gpus">--num_gpus</a> sets number of GPUs to use during experiment launch.</p>
<p><a href="reference/#fitpy-gpus_per_net">--gpus_per_net</a> is a maximum number of GPUs to use per single experiment.</p>
<p><a href="reference/#fitpy-num_workers">--num_workers</a> sets number of workers to use.</p>
<p><a href="reference/#fitpy-cache">--cache</a> points to a cache folder to store the temporary data.</p>
<p>Other parameters can be found in the <a href="reference/#fit-script-arguments">fit script reference</a></p>
<h3 id="launching-tasks">Launching tasks</h3>
<p><code>task.py</code> script is designed to launch experiment training.</p>
<p>Tasks must be defined in the project python scope and marked by an 
annotation like this:</p>
<pre><code class="python">from musket_core import tasks, model
@tasks.task
def measure2(m: model.ConnectedModel):
    return result
</code></pre>

<p>In order to run the experiment or a number of experiments,   </p>
<p>A typical command line may look like this:</p>
<p><code>python -m musket_core.task --project "path/to/project" --name "experiment_name" --task "task_name" --num_gpus=1 --gpus_per_net=1 --num_workers=1 --cache "path/to/cache/folder"</code></p>
<p><a href="reference/#taskpy-project">--project</a> points to the root of the <a href="#project-structure">project</a></p>
<p><a href="reference/#taskpy-name">--name</a> is the name of the project sub-folder containing experiment yaml file.</p>
<p><a href="reference/#taskpy-name">--task</a> is the name of the task function.</p>
<p><a href="reference/#taskpy-num_gpus">--num_gpus</a> sets number of GPUs to use during experiment launch.</p>
<p><a href="reference/#taskpy-gpus_per_net">--gpus_per_net</a> is a maximum number of GPUs to use per single experiment.</p>
<p><a href="reference/#taskpy-num_workers">--num_workers</a> sets number of workers to use.</p>
<p><a href="reference/#taskpy-cache">--cache</a> points to a cache folder to store the temporary data.</p>
<p>Other parameters can be found in the <a href="reference/#task-script-arguments">task script reference</a></p>
<h3 id="launching-project-analysis">Launching project analysis</h3>
<p><code>analize.py</code> script is designed to launch project-scope analysis.</p>
<p>Note that only experiments, which training is already finished will be covered.</p>
<p><code>musket analize --inputFolder "path/to/project"</code></p>
<p><a href="reference/#analyzepy-inputfolder">--inputFolder</a> points to a folder to search for finished experiments in. Typically, project root.</p>
<p>Other parameters can be found in the <a href="reference/#analyze-script-arguments">analyze script reference</a></p>
<h2 id="general-train-properties">General train properties</h2>
<p>Lets take our standard example and check the following set of instructions:</p>
<pre><code class="yaml">imports: [ layers, preprocessors ]
testSplit: 0.4
optimizer: Adam #Adam optimizer is a good default choice
batch: 12 #Our batch size will be 16
metrics: #We would like to track some metrics
  - binary_accuracy
  - matthews_correlation
primary_metric: val_binary_accuracy #and the most interesting metric is val_binary_accuracy
loss: binary_crossentropy #We use simple binary_crossentropy loss
</code></pre>

<p><a href="reference/#imports">imports</a> imports python files that are not located in  <code>modules</code> folder of the project and make their properly annotated contents to be available to be referred from YAML. Files from the modules folder are imported automatically</p>
<p><a href="reference/#testsplit">testSplit</a> Splits the train set into two parts, using one part for train and leaving the other untouched for a later testing.
The split is shuffled. </p>
<p><a href="reference/#optimizer">optimizer</a> sets the optimizer.</p>
<p><a href="reference/#batch">batch</a> sets the training batch size.</p>
<p><a href="reference/#metrics">metrics</a> sets the metrics to track during the training process. Metric calculation results will be printed in the console and to <code>metrics</code> folder of the experiment.</p>
<p><a href="reference/#primary_metric">primary_metric</a> Metric to track during the training process. Metric calculation results will be printed in the console and to <code>metrics</code> folder of the experiment.
Besides tracking, this metric will be also used by default for metric-related activity, in example, for decision regarding which epoch results are better.</p>
<p><a href="reference/#loss">loss</a> sets the loss function. if your network has multiple outputs, you also may pass a list of loss functions (one per output) </p>
<p>Framework supports composing loss as a weighted sum of predefined loss functions. For example, following construction</p>
<pre><code class="yaml">loss: binary_crossentropy+0.1*dice_loss
</code></pre>

<p>will result in loss function which is composed from <code>binary_crossentropy</code> and <code>dice_loss</code> functions.</p>
<p>There are many more properties to check in <a href="reference/#pipeline-root-properties">Reference of root properties</a></p>
<h2 id="definining-networks">Definining networks</h2>
<p>Lets check the next part of our example:</p>
<pre><code class="yaml">declarations:
  collapseConv:
    parameters: [ filters,size, pool]
    body:
      - conv1d: [filters,size,relu ]
      - conv1d: [filters,size,relu ]
      - batchNormalization: {}
      - collapse: pool
  net:
    - repeat(2):
      - collapseConv: [ 20, 7, 10 ]

    - cudnnlstm: [40, true ]
    - cudnnlstm: [40, true ]
    - attention: 718
    - dense: [3, sigmoid]
architecture: net
</code></pre>

<p>Here, <code>declarations</code> instruction set up network blocks <code>collapseConv</code> and <code>net</code>.
<code>collapseConv</code> block defines its input parameters (those are YAML-level parameters, not actual network tensors),
and <code>body</code> defines the sub-blocks of the block.</p>
<p><code>net</code> block has no parameters, so its sub-blocks come right inside the <code>net</code>.
Following are built-in layers used inside both blocks:</p>
<ul>
<li><a href="reference/#conv1d">conv1d</a></li>
<li><a href="reference/#batchnormalization">batchNormalization</a></li>
<li><a href="reference/#cudnnlstm">cudnnlstm</a></li>
<li><a href="reference/#attention">attention</a></li>
<li><a href="reference/#dense">dense</a></li>
</ul>
<p>And data / control-flow instructions:</p>
<ul>
<li><a href="reference/#collapse">collapse</a></li>
<li><a href="reference/#repeat">repeat</a></li>
</ul>
<p>Also, <code>net</code> block uses <code>collapseConv</code> block by stating <code>collapseConv: [ 20, 7, 10 ]</code>, where <code>collapseConv</code> ordered parameters <code>[ 20, 7, 10 ]</code> come in YAML array.</p>
<p><a href="reference/#architecture">architecture</a> instruction sets <code>net</code> block as the entry point for the whole experiment.</p>
<h3 id="built-in-nn-layers">Built-in NN layers</h3>
<p>There are a lot of built-in NN layers, basically, we support all layers that are supported by Keras.</p>
<p>Here are just a few:</p>
<ul>
<li><a href="reference/#dropout">Dropout</a></li>
<li><a href="reference/#lstm">LSTM</a></li>
<li><a href="reference/#globalmaxpool1d">GlobalMaxPool1D</a></li>
<li><a href="reference/#batchnormalization">BatchNormalization</a></li>
<li><a href="reference/#concatenate">Concatenate</a></li>
<li><a href="reference/#conv2d">Conv2D</a></li>
<li><a href="reference/#dense">Dense</a></li>
</ul>
<p>More can be found here: <a href="reference/#layer-types">Layer types</a></p>
<h3 id="control-layers">Control layers</h3>
<p><a href="reference/#utility-layers">Utility layers</a> can be used to set control and data flow inside their bodies. Here are some examples:</p>
<h4 id="simple-data-flow-constructions">Simple Data Flow constructions</h4>
<pre><code class="yaml">  inceptionBlock:
    parameters: [channels]
    with:
      padding: same
    body:
      - split-concatenate:
        - Conv2D: [channels,1]
        - seq:
          - Conv2D: [channels*3,1]
          - Conv2D: [channels,3]
        - seq:
            - Conv2D: [channels*4,1]
            - Conv2D: [channels,1]
        - seq:
            - Conv2D: [channels,2]
            - Conv2D: [channels,1]            
</code></pre>

<h4 id="repeat-and-with">Repeat and With</h4>
<pre><code class="yaml">declarations:
  convBlock:
    parameters: [channels]
    with:
      padding: same
    body:
      - repeat(5):
        - Conv2D: [channels*_,1]
  net:
      - convBlock: [120]
</code></pre>

<h4 id="conditional-layers">Conditional layers</h4>
<pre><code class="yaml">declarations:
  c2d:
    parameters: [size, pool,mp]
    body:
      - Conv1D: [100,size,relu]
      - Conv1D: [100,size,relu]
      - Conv1D: [100,size,relu]
      - if(mp):
          MaxPool1D: pool
  net:
      - c2d: [4,4,False]
      - c2d: [4,4,True]
      - Dense: [4, sigmoid]
</code></pre>

<h4 id="shared-weights">Shared Weights</h4>
<pre><code class="yaml">#Basic example with sequencial model
declarations:
  convBlock:
    parameters: [channels]
    shared: true
    with:
      padding: same
    body:
      - Conv2D: [channels,1]
      - Conv2D: [channels,1]
  net:
      - convBlock: [3] #weights of convBlock will be shared between invocations
      - convBlock: [3] #weights of convBlock will be shared between invocations
</code></pre>

<h4 id="wrapper-layers">Wrapper layers</h4>
<pre><code class="yaml">  net:
    #- gaussianNoise: 0.0001

    #- collapseConv: [ 20, 7, 10 ]
    #- collapseConv: [ 20, 7, 10 ]
    - bidirectional:
        - cudnnlstm: [30, true ]
    - bidirectional:
        - cudnnlstm: [50, true ]
    - attention: 200
    - dense: [64, relu]
    - dense: [3, sigmoid]
</code></pre>

<h4 id="manually-controlling-data-flow">Manually controlling data flow</h4>
<pre><code class="yaml">  net:
    inputs: [i1,i2]
    outputs: [d1,d2]
    body:
      - c2d:
          args: [4,4]
          name: o1
          inputs: i1
      - c2d:
          args: [4,4]
          name: o2
          inputs: i2
      - dense:
          units: 4
          activation: sigmoid
          inputs: o1
          name: d1
      - dense:
          units: 4
          activation: sigmoid
          inputs: o2
          name: d2
</code></pre>

<p>Full list can be found <a href="reference/#utility-layers">here</a></p>
<h2 id="datasets">Datasets</h2>
<p>Datasets allow to define the ways to load data for this particular project.
As this pipeline is designed to support an arbitrary data, the only way to add dataset is to put in some custom python code and then refer it from YAML:</p>
<pre><code class="python">class DischargeData(datasets.DataSet):

    def __init__(self,ids,normalize=True, flatten=False):
        self.normalize=normalize
        self.flatten = flatten
        self.cache={}
        self.ids=list(set(list(ids)))

    def __getitem__(self, item):
        item=self.ids[item]
        if item in self.cache:
            return self.cache[item]
        ps= PredictionItem(item,getX(item,self.normalize),getY(item,self.flatten))
        #self.cache[item]=ps
        return ps

    def __len__(self):
        return len(self.ids)

def getTrain(normalize=True,flatten=False)-&gt;datasets.DataSet:
    return DischargeData(ids,normalize,flatten)

def getTest(normalize=True,flatten=False)-&gt;datasets.DataSet:
    return DischargeData(test_ids,normalize,flatten)    
</code></pre>

<p>Now, if this python code sits somewhere in python files located in <code>modules</code> folder of the project, and that file is referred by <a href="reference/#imports">imports</a> instruction, following YAML can refer it:</p>
<pre><code class="yaml">dataset:
  getTrain: [false,false]
datasets:
  test:
    getTest: [false,false]
</code></pre>

<p><a href="reference/#dataset">dataset</a> sets the main training dataset.</p>
<p><a href="reference/#datasets">datasets</a> sets up a list of available data sets to be referred by other entities.</p>
<h2 id="callbacks">Callbacks</h2>
<p>Lets check the following block from out main example:</p>
<pre><code class="yaml">callbacks: #Let's configure some minimal callbacks
  EarlyStopping:
    patience: 100
    monitor: val_binary_accuracy
    verbose: 1
  ReduceLROnPlateau:
    patience: 8
    factor: 0.5
    monitor: val_binary_accuracy
    mode: auto
    cooldown: 5
    verbose: 1
</code></pre>

<p>We set up two callback, which are being invoked during the training time: 
<a href="reference/#earlystopping">EarlyStopping</a> that monitors metrics and stops training if results doesnt get better, and <code>val_binary_accuracy</code> and <a href="reference/#reducelronplateau">ReduceLROnPlateau</a>, which reduces learning rate for the same reason.</p>
<p>The list of callbacks can be found <a href="reference/#callbacks">here</a></p>
<h2 id="stages">Stages</h2>
<p>Sometimes you need to split your training into several stages. You can easily do it by adding several stage entries
in your experiment configuration file.</p>
<p><a href="reference/#stages">stages</a> instruction allows to set up stages of the train process, where for each stage it is possible to set some specific training options like the number of epochs, learning rate, loss, callbacks, etc.
Full list of stage properties can be found <a href="reference/#stage-properties">here</a>.</p>
<pre><code class="yaml">stages:
  - epochs: 100 #Let's go for 100 epochs
  - epochs: 100 #Let's go for 100 epochs
  - epochs: 100 #Let's go for 100 epochs
</code></pre>

<pre><code class="yaml">stages:
  - epochs: 6 #Train for 6 epochs
    negatives: none #do not include negative examples in your training set 
    validation_negatives: real #validation should contain all negative examples    

  - lr: 0.0001 #let's use different starting learning rate
    epochs: 6
    negatives: real
    validation_negatives: real

  - loss: lovasz_loss #let's override loss function
    lr: 0.00001
    epochs: 6
    initial_weights: ./fpn-resnext2/weights/best-0.1.weights #let's load weights from this file    
</code></pre>

<h2 id="balancing-your-data">Balancing your data</h2>
<p>One common case is the situation when part of your images does not contain any objects of interest, like in 
<a href="https://www.kaggle.com/c/airbus-ship-detection/overview">Airbus ship detection challenge</a>. More over your data may
be to heavily inbalanced, so you may want to rebalance it. Alternatively you may want to inject some additional
images that do not contain objects of interest to decrease amount of false positives that will be produced by the framework.</p>
<p>These scenarios are supported by <a href="reference/#negatives">negatives</a> and 
<a href="reference/#validation_negatives">validation_negatives</a> settings of training stage configuration,
these settings accept following values:</p>
<ul>
<li>none - exclude negative examples from the data</li>
<li>real - include all negative examples </li>
<li>integer number(1 or 2 or anything), how many negative examples should be included per one positive example   </li>
</ul>
<pre><code class="yaml">stages:
  - epochs: 6 #Train for 6 epochs
    negatives: none #do not include negative examples in your training set 
    validation_negatives: real #validation should contain all negative examples    

  - lr: 0.0001 #let's use different starting learning rate
    epochs: 6
    negatives: real
    validation_negatives: real

  - loss: lovasz_loss #let's override loss function
    lr: 0.00001
    epochs: 6
    initial_weights: ./fpn-resnext2/weights/best-0.1.weights #let's load weights from this file    
</code></pre>

<p>if you are using this setting your dataset class must support <code>isPositive</code> method which returns true for indexes
which contain positive examples: </p>
<pre><code class="python">    def isPositive(self, item):
        pixels=self.ddd.get_group(self.ids[item])[&quot;EncodedPixels&quot;]
        for mask in pixels:
            if isinstance(mask, str):
                return True;
        return False
</code></pre>

<h2 id="advanced-learning-rates">Advanced learning rates</h2>
<h3 id="dynamic-learning-rates">Dynamic learning rates</h3>
<p><img alt="Example" src="https://github.com/bckenstler/CLR/blob/master/images/triangularDiag.png?raw=true" /></p>
<p>As told in <a href="https://arxiv.org/abs/1506.01186">Cyclical learning rates for training neural networks</a> CLR policies can provide quicker converge for some neural network tasks and architectures. </p>
<p><img alt="Example2" src="https://github.com/bckenstler/CLR/raw/master/images/cifar.png" /></p>
<p>We support them by adopting Brad Kenstler <a href="https://github.com/bckenstler/CLR">CLR callback</a> for Keras.</p>
<p>If you want to use them, just add <a href="reference/#cycliclr">CyclicLR</a> in your experiment configuration file as shown below: </p>
<pre><code class="yaml">callbacks:
  EarlyStopping:
    patience: 40
    monitor: val_binary_accuracy
    verbose: 1
  CyclicLR:
     base_lr: 0.0001
     max_lr: 0.01
     mode: triangular2
     step_size: 300
</code></pre>

<p>There are also <a href="reference/#reducelronplateau">ReduceLROnPlateau</a> and <a href="reference/#lrvariator">LRVariator</a> options to modify learning rate on the fly.</p>
<h3 id="lr-finder">LR Finder</h3>
<p><a href="https://arxiv.org/abs/1506.01186">Estimating optimal learning rate for your model</a> is an important thing, we support this by using slightly changed 
version of <a href="https://github.com/surmenok/keras_lr_finder">Pavel Surmenok - Keras LR Finder</a></p>
<pre><code class="python">cfg= segmentation.parse(people-1.yaml)
ds=SimplePNGMaskDataSet(&quot;./train&quot;,&quot;./train_mask&quot;)
finder=cfg.lr_find(ds,start_lr=0.00001,end_lr=1,epochs=5)
finder.plot_loss(n_skip_beginning=20, n_skip_end=5)
plt.show()
finder.plot_loss_change(sma=20, n_skip_beginning=20, n_skip_end=5, y_lim=(-0.01, 0.01))
plt.show()
</code></pre>

<p>will result in this couple of helpful images: </p>
<p><img alt="image" src="https://camo.githubusercontent.com/b41aeaff00fb7b214b5eb2e5c151e7e353a7263e/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f313630302f312a48566a5f344c57656d6a764f57762d63514f397939672e706e67" /></p>
<p><img alt="image" src="https://camo.githubusercontent.com/834996d32bbd2edf7435c5e105b53a6b447ef083/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f313630302f312a38376d4b715f586f6d59794a4532396c39314b3064772e706e67" /></p>
<h2 id="preprocessors"><a href="reference/#preprocessors">Preprocessors</a></h2>
<p><a href="reference/#preprocessors">Preprocessors</a> are the custom python functions that transform dataset. </p>
<p>Such functions should be defined in python files that are in a project scope (<code>modules</code>) folder and imported.
Preprocessing functions should be also marked with <code>@preprocessing.dataset_preprocessor</code> annotation.</p>
<p><a href="reference/#preprocess">preprocess</a> instruction then can be used to chain preprocessors as needed for this particular experiment, and even cache the result on disk to be reused between experiments.</p>
<pre><code class="yaml">preprocess:
     - rescale: 10
     - get_delta_from_average
     - disk-cache
</code></pre>

<pre><code class="python">import numpy as np
from musket_core import preprocessing

def moving_average(input, n=1000) :
    ret = np.cumsum(input, dtype=float, axis=0)
    ret[n:] = ret[n:] - ret[:-n]
    ret[0:n] = ret[-n:]
    return ret / n

@preprocessing.dataset_preprocessor
def get_delta_from_average(input):
    m = moving_average(input[:, :])
    m1 = moving_average(input[:, :],100)
    #m2 = moving_average(input[:, :], 10000)
    d = input[:, :] - m
    d1 = input[:, :] - m1
    #d2 = input[:, :] - m2

    input=input/input.max()
    d1 = d1 / d1.max()
   # d2 = d2 / d2.max()
    d = d / d.max()
    return np.concatenate([d,d1,input])

@preprocessing.dataset_preprocessor
def rescale(input,size):
    mean=np.mean(np.reshape(input, (input.shape[0] // size ,size, 3)), axis=1)
    max=np.max(np.reshape(input, (input.shape[0] // size, size, 3)), axis=1)
    min = np.min(np.reshape(input, (input.shape[0] // size, size, 3)), axis=1)
    return np.concatenate([mean,max,min])
</code></pre>

<h2 id="how-to-check-training-results">How to check training results</h2>
<p>In experiment folder <code>metrics</code> subfolder contain a CSV report file for each fold and stage.</p>
<p><code>summary.yaml</code> file in the experiment folder contain the statistics for the whole experiment.</p>
              
            </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href=".." style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="reference/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js" defer></script>
      <script src="../search/main.js" defer></script>
    <script type="text/javascript" defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(false);
        };
    </script>

</body>
</html>
