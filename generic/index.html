<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>User guide - Musket ML</title>
        <link href="../css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../css/font-awesome.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
        <![endif]-->

        <script src="../js/jquery-1.10.2.min.js" defer></script>
        <script src="../js/bootstrap-3.0.3.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body>

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
            <div class="container">

                <!-- Collapsed navigation -->
                <div class="navbar-header">
                    <!-- Expander button -->
                    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand" href="..">Musket ML</a>
                </div>

                <!-- Expanded navigation -->
                <div class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li >
                                <a href="..">Home</a>
                            </li>
                            <li class="dropdown active">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Generic <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li class="active">
    <a href="./">User guide</a>
</li>
                                    
<li >
    <a href="reference/">Reference</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Segmentation <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li >
    <a href="../segmentation/">User guide</a>
</li>
                                    
<li >
    <a href="../segmentation/reference/">Reference</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Classification <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li >
    <a href="../classification/">User guide</a>
</li>
                                    
<li >
    <a href="../classification/reference/">Reference</a>
</li>
                                </ul>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav navbar-right">
                        <li>
                            <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li >
                                <a rel="next" href="..">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li >
                                <a rel="prev" href="reference/">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
                <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="main active"><a href="#reasons-to-use-generic-pipeline">Reasons to use Generic Pipeline</a></li>
        <li class="main "><a href="#installation">Installation</a></li>
        <li class="main "><a href="#project-structure">Project structure</a></li>
        <li class="main "><a href="#launching">Launching</a></li>
        <li class="main "><a href="#general-train-properties">General train properties</a></li>
        <li class="main "><a href="#definining-networks">Definining networks</a></li>
            <li><a href="#built-in-nn-layers">Built-in NN layers</a></li>
            <li><a href="#control-layers">Control layers</a></li>
        <li class="main "><a href="#datasets">Datasets</a></li>
        <li class="main "><a href="#callbacks">Callbacks</a></li>
        <li class="main "><a href="#stages">Stages</a></li>
        <li class="main "><a href="#preprocessors">Preprocessors</a></li>
        <li class="main "><a href="#how-to-check-training-results">How to check training results</a></li>
    </ul>
</div></div>
                <div class="col-md-9" role="main">

<h1 id="reasons-to-use-generic-pipeline">Reasons to use Generic Pipeline</h1>
<p>TODO: add more text from a general promo here</p>
<p>Generic Pipeline was developed with a focus of enabling to make fast and simply-declared experiments, which can be easily stored, reproduced and compared to each other.</p>
<p>It provides the following features:</p>
<ul>
<li>Allows to describe experiments in a compact and expressive way</li>
<li>Provides a way to store and compare experiments in order to methodically find the best deap learning solution</li>
<li>Easy to share experiments and their results to work in a team</li>
<li>Allows to define custom neural networks in a declarative style, by building it from blocks</li>
<li>Provides great flexibility and extensibility via support of custom substances</li>
</ul>
<p>All experiments are declared in YAML dialect with lots of defaults, allowing to describe an initial experiment in several lines and then set more details if needed.</p>
<p>Here is a relatively complex example, most of the statements can be omitted:</p>
<pre><code class="yaml">imports: [ layers, preprocessors ]
declarations:
  collapseConv:
    parameters: [ filters,size, pool]
    body:
      - conv1d: [filters,size,relu ]
      - conv1d: [filters,size,relu ]
      - batchNormalization: {}
      - collapse: pool
  net:
    - repeat(2):
      - collapseConv: [ 20, 7, 10 ]

    - cudnnlstm: [40, true ]
    - cudnnlstm: [40, true ]
    - attention: 718
    - dense: [3, sigmoid]
  preprocess:
     - rescale: 10
     - get_delta_from_average
     - cache
preprocessing: preprocess
testSplit: 0.4
architecture: net
optimizer: Adam #Adam optimizer is a good default choice
batch: 12 #Our batch size will be 16
metrics: #We would like to track some metrics
  - binary_accuracy
  - matthews_correlation
primary_metric: val_binary_accuracy #and the most interesting metric is val_binary_accuracy
callbacks: #Let's configure some minimal callbacks
  EarlyStopping:
    patience: 100
    monitor: val_binary_accuracy
    verbose: 1
  ReduceLROnPlateau:
    patience: 8
    factor: 0.5
    monitor: val_binary_accuracy
    mode: auto
    cooldown: 5
    verbose: 1
loss: binary_crossentropy #We use simple binary_crossentropy loss
stages:
  - epochs: 100 #Let's go for 100 epochs
  - epochs: 100 #Let's go for 100 epochs
  - epochs: 100 #Let's go for 100 epochs
</code></pre>

<h1 id="installation">Installation</h1>
<p>TODO: make sure this actually works.
<code>pip install generic_pipeline</code></p>
<h1 id="project-structure">Project structure</h1>
<p>Each experiment is simply a folder with YAML file inside, it is easy to store and run experiment.</p>
<p>Project is a folder with the following structure inside:</p>
<ul>
<li><strong>project_name</strong></li>
<li><strong>experiments</strong><ul>
<li><strong>experiment1</strong></li>
<li>config.yaml</li>
<li><strong>experiment2</strong></li>
<li>config.yaml</li>
<li>summary.yaml</li>
<li><strong>metrics</strong><ul>
<li>metrics-0.0.csv</li>
<li>metrics-1.0.csv</li>
<li>metrics-2.0.csv</li>
<li>metrics-3.0.csv</li>
<li>metrics-4.0.csv</li>
</ul>
</li>
</ul>
</li>
<li><strong>modules</strong><ul>
<li>main.py</li>
<li>arbitrary_module.py</li>
</ul>
</li>
<li>common.yaml</li>
</ul>
<p>The only required part is <code>experiments</code> folder with at least one arbitrary-named experiment subfolder having <code>config.yaml</code> file inside.
Each experiment starts with its configuration, other files are being added by the pipeline during th training.</p>
<p><code>common.yaml</code> file may be added to set instructions, which will be applied to all project experiments.</p>
<p><code>modules</code> folder may be added to set python files in project scope, so custom yaml declarations can be mapped 
onto python classes and functions defined inside such files. <code>main.py</code> will be always executed, other files require <a href="reference/#imports">imports</a> instruction. </p>
<p><code>summary.yaml</code> and <code>metrics</code> folders inside each experiment appear after the experiment training is executed.</p>
<p>There are more potential files, like intermediate results cache files etc.</p>
<h1 id="launching">Launching</h1>
<p>TODO</p>
<h1 id="general-train-properties">General train properties</h1>
<p>Lets take our standard example and check the following set of instructions:</p>
<pre><code class="yaml">imports: [ layers, preprocessors ]
testSplit: 0.4
optimizer: Adam #Adam optimizer is a good default choice
batch: 12 #Our batch size will be 16
metrics: #We would like to track some metrics
  - binary_accuracy
  - matthews_correlation
primary_metric: val_binary_accuracy #and the most interesting metric is val_binary_accuracy
loss: binary_crossentropy #We use simple binary_crossentropy loss
</code></pre>

<p><a href="reference/#imports">imports</a> imports python files from <code>modules</code> folder of the project and make their properly annotated contents to be available to be referred from YAML.</p>
<p><a href="reference/#testsplit">testSplit</a> Splits the train set into two parts, using one part for train and leaving the other untouched for a later testing.
The split is shuffled.</p>
<p><a href="reference/#optimizer">optimizer</a> sets the optimizer.</p>
<p><a href="reference/#batch">batch</a> sets the training batch size.</p>
<p><a href="reference/#metrics">metrics</a> sets the metrics to track during the training process. Metric calculation results will be printed in the console and to <code>metrics</code> folder of the experiment.</p>
<p><a href="reference/#primary_metric">primary_metric</a> Metric to track during the training process. Metric calculation results will be printed in the console and to <code>metrics</code> folder of the experiment.
Besides tracking, this metric will be also used by default for metric-related activity, in example, for decision regarding which epoch results are better.</p>
<p><a href="reference/#loss">loss</a> sets the loss function.</p>
<p>There are many more properties to check in <a href="reference/#pipeline-root-properties">Reference of root properties</a></p>
<h1 id="definining-networks">Definining networks</h1>
<p>Lets check the next part of our example:</p>
<pre><code class="yaml">declarations:
  collapseConv:
    parameters: [ filters,size, pool]
    body:
      - conv1d: [filters,size,relu ]
      - conv1d: [filters,size,relu ]
      - batchNormalization: {}
      - collapse: pool
  net:
    - repeat(2):
      - collapseConv: [ 20, 7, 10 ]

    - cudnnlstm: [40, true ]
    - cudnnlstm: [40, true ]
    - attention: 718
    - dense: [3, sigmoid]
architecture: net
</code></pre>

<p>Here, <code>declarations</code> instruction set up network blocks <code>collapseConv</code> and <code>net</code>.
<code>collapseConv</code> block defines its input parameters (those are YAML-level parameters, not actual network tensors),
and <code>body</code> defines the sub-blocks of the block.</p>
<p><code>net</code> block has no parameters, so its sub-blocks come right inside the <code>net</code>.
Following are built-in layers used inside both blocks:</p>
<ul>
<li><a href="reference/#conv1d">conv1d</a></li>
<li><a href="reference/#batchnormalization">batchNormalization</a></li>
<li><a href="reference/#cudnnlstm">cudnnlstm</a></li>
<li><a href="reference/#attention">attention</a></li>
<li><a href="reference/#dense">dense</a></li>
</ul>
<p>And data / control-flow instructions:</p>
<ul>
<li><a href="reference/#collapse">collapse</a></li>
<li><a href="reference/#repeat">repeat</a></li>
</ul>
<p>Also, <code>net</code> block uses <code>collapseConv</code> block by stating <code>collapseConv: [ 20, 7, 10 ]</code>, where <code>collapseConv</code> ordered parameters <code>[ 20, 7, 10 ]</code> come in YAML array.</p>
<p><a href="reference/#architecture">architecture</a> instruction sets <code>net</code> block as the entry point for the whole experiment.</p>
<h2 id="built-in-nn-layers">Built-in NN layers</h2>
<p>There are a lot of built-in NN layers, basically, all of those supported by Keras.</p>
<p>Here are just a few:</p>
<ul>
<li><a href="reference/#dropout">Dropout</a></li>
<li><a href="reference/#lstm">LSTM</a></li>
<li><a href="reference/#globalmaxpool1d">GlobalMaxPool1D</a></li>
<li><a href="reference/#batchnormalization">BatchNormalization</a></li>
<li><a href="reference/#concatenate">Concatenate</a></li>
<li><a href="reference/#conv2d">Conv2D</a></li>
<li><a href="reference/#dense">Dense</a></li>
</ul>
<p>More can be found here: <a href="reference/#layer-types">Layer types</a></p>
<h2 id="control-layers">Control layers</h2>
<p><a href="reference/#utility-layers">Utility layers</a> can be used to set control and data flow inside their bodies. Here are some examples:</p>
<h3 id="simple-data-flow-constructions">Simple Data Flow constructions</h3>
<pre><code class="yaml">  inceptionBlock:
    parameters: [channels]
    with:
      padding: same
    body:
      - split-concatenate:
        - Conv2D: [channels,1]
        - seq:
          - Conv2D: [channels*3,1]
          - Conv2D: [channels,3]
        - seq:
            - Conv2D: [channels*4,1]
            - Conv2D: [channels,1]
        - seq:
            - Conv2D: [channels,2]
            - Conv2D: [channels,1]            
</code></pre>

<h3 id="repeat-and-with">Repeat and With</h3>
<pre><code class="yaml">declarations:
  convBlock:
    parameters: [channels]
    with:
      padding: same
    body:
      - repeat(5):
        - Conv2D: [channels*_,1]
  net:
      - convBlock: [120]
</code></pre>

<h3 id="conditional-layers">Conditional layers</h3>
<pre><code class="yaml">declarations:
  c2d:
    parameters: [size, pool,mp]
    body:
      - Conv1D: [100,size,relu]
      - Conv1D: [100,size,relu]
      - Conv1D: [100,size,relu]
      - if(mp):
          MaxPool1D: pool
  net:
      - c2d: [4,4,False]
      - c2d: [4,4,True]
      - Dense: [4, sigmoid]
</code></pre>

<h3 id="shared-weights">Shared Weights</h3>
<pre><code class="yaml">#Basic example with sequencial model
declarations:
  convBlock:
    parameters: [channels]
    shared: true
    with:
      padding: same
    body:
      - Conv2D: [channels,1]
      - Conv2D: [channels,1]
  net:
      - convBlock: [3] #weights of convBlock will be shared between invocations
      - convBlock: [3] #weights of convBlock will be shared between invocations
</code></pre>

<h3 id="wrapper-layers">Wrapper layers</h3>
<pre><code class="yaml">  net:
    #- gaussianNoise: 0.0001

    #- collapseConv: [ 20, 7, 10 ]
    #- collapseConv: [ 20, 7, 10 ]
    - bidirectional:
        - cudnnlstm: [30, true ]
    - bidirectional:
        - cudnnlstm: [50, true ]
    - attention: 200
    - dense: [64, relu]
    - dense: [3, sigmoid]
</code></pre>

<h3 id="manually-controlling-data-flow">Manually controlling data flow</h3>
<pre><code class="yaml">  net:
    inputs: [i1,i2]
    outputs: [d1,d2]
    body:
      - c2d:
          args: [4,4]
          name: o1
          inputs: i1
      - c2d:
          args: [4,4]
          name: o2
          inputs: i2
      - dense:
          units: 4
          activation: sigmoid
          inputs: o1
          name: d1
      - dense:
          units: 4
          activation: sigmoid
          inputs: o2
          name: d2
</code></pre>

<p>Full list can be found <a href="reference/#utility-layers">here</a></p>
<h1 id="datasets">Datasets</h1>
<p>Datasets allow to define the ways to load data for this particular project.
As this pipeline is designed to support an arbitrary data, the only way to add dataset is to put in some custom python code and then refer it from YAML:</p>
<pre><code class="yaml">class DischargeData(datasets.DataSet):

    def __init__(self,ids,normalize=True, flatten=False):
        self.normalize=normalize
        self.flatten = flatten
        self.cache={}
        self.ids=list(set(list(ids)))

    def __getitem__(self, item):
        item=self.ids[item]
        if item in self.cache:
            return self.cache[item]
        ps= PredictionItem(item,getX(item,self.normalize),getY(item,self.flatten))
        #self.cache[item]=ps
        return ps

    def __len__(self):
        return len(self.ids)

def getTrain(normalize=True,flatten=False)-&gt;datasets.DataSet:
    return DischargeData(ids,normalize,flatten)

def getTest(normalize=True,flatten=False)-&gt;datasets.DataSet:
    return DischargeData(test_ids,normalize,flatten)    
</code></pre>

<p>Now, if this python code sits somewhere in python files located in <code>modules</code> folder of the project, and that file is referred by <a href="reference/#imports">imports</a> instruction, following YAML can refer it:</p>
<pre><code class="yaml">dataset:
  getTrain: [false,false]
datasets:
  test:
    getTest: [false,false]
</code></pre>

<p><a href="reference/#dataset">dataset</a> sets the main training dataset.</p>
<p><a href="reference/#datasets">datasets</a> sets up a list of available data sets to be referred by other entities.</p>
<h1 id="callbacks">Callbacks</h1>
<p>Lets check the following block from out main example:</p>
<pre><code class="yaml">callbacks: #Let's configure some minimal callbacks
  EarlyStopping:
    patience: 100
    monitor: val_binary_accuracy
    verbose: 1
  ReduceLROnPlateau:
    patience: 8
    factor: 0.5
    monitor: val_binary_accuracy
    mode: auto
    cooldown: 5
    verbose: 1
</code></pre>

<p>We set up two callback, which are being invoked during the training time: 
<a href="reference/#earlystopping">EarlyStopping</a> that monitors metrics and stops training if results doesnt get better, and <code>val_binary_accuracy</code> and <a href="reference/#reducelronplateau">ReduceLROnPlateau</a>, which reduces learning rate for the same reason.</p>
<p>The list of callbacks can be found <a href="reference/#callbacks">here</a></p>
<h1 id="stages">Stages</h1>
<p><a href="reference/#stages">stages</a> instruction allows to set up stages of the train process, where for each stage it is possible to set some specific training options like the number of epochs, learning rate, loss, callbacks, etc.
Full list of stage properties can be found <a href="reference/#stage-properties">here</a>.</p>
<pre><code class="yaml">stages:
  - epochs: 100 #Let's go for 100 epochs
  - epochs: 100 #Let's go for 100 epochs
  - epochs: 100 #Let's go for 100 epochs
</code></pre>

<h1 id="preprocessors"><a href="reference/#preprocessors">Preprocessors</a></h1>
<p><a href="reference/#preprocessors">Preprocessors</a> are the custom python functions that transform dataset. </p>
<p>Such functions should be defined in python files that are in a project scope (<code>modules</code>) folder and imported.
Preprocessing functions should be also marked with <code>@preprocessing.dataset_preprocessor</code> annotation.</p>
<p><a href="reference/#preprocess">preprocess</a> instruction then can be used to chain preprocessors as needed for this particular experiment, and even cache the result on disk to be reused between experiments.</p>
<pre><code class="yaml">preprocess:
     - rescale: 10
     - get_delta_from_average
     - disk-cache
</code></pre>

<pre><code class="python">import numpy as np
from musket_core import preprocessing

def moving_average(input, n=1000) :
    ret = np.cumsum(input, dtype=float, axis=0)
    ret[n:] = ret[n:] - ret[:-n]
    ret[0:n] = ret[-n:]
    return ret / n

@preprocessing.dataset_preprocessor
def get_delta_from_average(input):
    m = moving_average(input[:, :])
    m1 = moving_average(input[:, :],100)
    #m2 = moving_average(input[:, :], 10000)
    d = input[:, :] - m
    d1 = input[:, :] - m1
    #d2 = input[:, :] - m2

    input=input/input.max()
    d1 = d1 / d1.max()
   # d2 = d2 / d2.max()
    d = d / d.max()
    return np.concatenate([d,d1,input])

@preprocessing.dataset_preprocessor
def rescale(input,size):
    mean=np.mean(np.reshape(input, (input.shape[0] // size ,size, 3)), axis=1)
    max=np.max(np.reshape(input, (input.shape[0] // size, size, 3)), axis=1)
    min = np.min(np.reshape(input, (input.shape[0] // size, size, 3)), axis=1)
    return np.concatenate([mean,max,min])
</code></pre>

<h1 id="how-to-check-training-results">How to check training results</h1>
<p>In experiment folder <code>metrics</code> subfolder contain a CSV report file for each fold and stage.</p>
<p><code>summary.yaml</code> file in the experiment folder contain the statistics for the whole experiment.</p></div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js" defer></script>
        <script src="../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form role="form">
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="Keyboard Shortcuts Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Keyboard Shortcuts</h4>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
